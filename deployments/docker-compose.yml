version: "3"

services:
  hasherapi:
    container_name: hasherapi
    build:
      context: ../
      dockerfile: build/hasherapi/Dockerfile
      args:
        - PORT=8088 
    environment:
      - HASHERAPI_CONSUL_HOST=consul:8500
      - HASHERAPI_CONSUL_CONFIGKEY=config/hasherapi
    depends_on:
      - consul
      - hasher
      - redis
      - graylog
      - kafka
    ports:
      - "8088:8088"

  redis:
    container_name: redis
    image: redis:4.0-alpine
    command:
      - 'redis-server'
      - '--loglevel ${REDIS_LOGLEVEL:-warning}'
      - '--databases 2'
      - '--maxmemory ${REDIS_MAXMEM:-50mb}'
      - '--maxmemory-policy ${REDIS_POLICY:-noeviction}'
      - '--requirepass ${REDIS_PASS:-123456789}'
    ports:
      - "6379:6379"

  hasher:
    container_name: hasher
    build:
      context: ../
      dockerfile: build/hasher/Dockerfile
    environment:
      - HASHER_CONSUL_HOST=consul:8500
      - HASHER_CONSUL_CONFIGKEY=config/hasher
    depends_on:
      - graylog
      - consul
    ports:
      - "8090:8090"

  graylog:
    container_name: graylog
    image: graylog/graylog:3.3
    environment:
      - GRAYLOG_HTTP_EXTERNAL_URI=http://127.0.0.1:9001/
    depends_on:
      - mongo
      - elasticsearch
    ports:
      - 9001:9000

  mongo:
    container_name: mongo
    image: mongo:3
  
  elasticsearch:
    container_name: elasticsearch
    image: docker.elastic.co/elasticsearch/elasticsearch-oss:6.8.10
    environment:
      - http.host=0.0.0.0
      - transport.host=localhost
      - network.host=0.0.0.0
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
    ulimits:
      memlock:
        soft: -1
        hard: -1
    deploy:
      resources:
        limits:
          memory: 1g

  consul:
    container_name: consul
    image: consul:1.10.3
    ports:
      - "8500:8500"

  zookeeper:
    container_name: zookeeper
    image: wurstmeister/zookeeper:3.4.6
    ports:
      - "2181:2181"
  
  kafka:
    container_name: kafka
    image: wurstmeister/kafka:2.13-2.8.1
    depends_on:
      - zookeeper
    ports:
      - "9093:9093"
    environment:
      KAFKA_BROKER_ID: '1'
      KAFKA_CREATE_TOPICS: 'http_calls:1:1'
      KAFKA_DELETE_TOPIC_ENABLE: 'true'
      KAFKA_ADVERTISED_HOST_NAME: 'kafka'
      KAFKA_ADVERTISED_PORT: '9092'
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'true'
      KAFKA_MESSAGE_MAX_BYTES: '200000000'
      KAFKA_LISTENERS: 'PLAINTEXT://:9092,SASL_PLAINTEXT://:9093'
      KAFKA_ADVERTISED_LISTENERS: 'PLAINTEXT://kafka:9092,SASL_PLAINTEXT://kafka:9093'
      KAFKA_SASL_ENABLED_MECHANISMS: 'PLAIN,SCRAM-SHA-256,SCRAM-SHA-512'
      KAFKA_OPTS: "-Djava.security.auth.login.config=/opt/kafka/config/kafka_server_jaas.conf"
      CUSTOM_INIT_SCRIPT: |-
        apk add libgcc;
        echo -e 'KafkaServer {\norg.apache.kafka.common.security.scram.ScramLoginModule required\n username="adminscram"\n password="admin-secret";\n org.apache.kafka.common.security.plain.PlainLoginModule required\n username="adminplain"\n password="admin-secret"\n user_adminplain="admin-secret";\n  };' > /opt/kafka/config/kafka_server_jaas.conf;
        /opt/kafka/bin/kafka-configs.sh --zookeeper zookeeper:2181 --alter --add-config 'SCRAM-SHA-256=[password=admin-secret-256],SCRAM-SHA-512=[password=admin-secret-512]' --entity-type users --entity-name adminscram
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock

  clickhouse:
    container_name: clickhouse
    image: yandex/clickhouse-server:21.11.9.1
    ports:
      - 9000:9000
    ulimits:
      nofile:
        soft: 262144
        hard: 262144
